import numpy as np
import fnmatch
import os
import scipy.io as sio
from tqdm import tqdm

def main():
    """Some of the dataset files generated by main.py are not size of 64. Bring altogether to make it suitable for training.
    """    
    train_matrices_names_list = fnmatch.filter(os.listdir('/raid/home/hyovin.kwak/PIE-NET_Dataset_Preparation/mat_after_main1'), '*.mat')
    train_matrices_names_list_num = len(train_matrices_names_list)

    batch_count = 0
    file_count = 0
    data = {'Training_data': np.zeros((64, 1), dtype = object)}
    for k in tqdm(range(train_matrices_names_list_num)):
        loadpath = "/raid/home/hyovin.kwak/PIE-NET_Dataset_Preparation/mat_after_main1/" + train_matrices_names_list[k]
        ref_mat = sio.loadmat(loadpath)['Training_data']
        end_count = sio.loadmat(loadpath)['batch_count'][0, 0]
        #if train_matrices_names_list[k][-7:] == "end.mat": 
        #    end_count = end_count - 1
        #elif train_matrices_names_list[k][-7:] != "end.mat": end_count += 1
        i = 0
        while i < end_count:
            down_sample_point = ref_mat[i, 0]['down_sample_point'][0, 0]
            edge_points_residual_vector = ref_mat[i, 0]['edge_points_residual_vector'][0, 0]
            corner_points_residual_vector = ref_mat[i, 0]['corner_points_residual_vector'][0, 0]
        
            # initialize memory arrays
            edge_points_label = ref_mat[i, 0]['edge_points_label'][0, 0][0, :][:, np.newaxis]
            corner_points_label = ref_mat[i, 0]['corner_points_label'][0, 0][0, :][:, np.newaxis]
            open_gt_pair_idx = ref_mat[i, 0]['open_gt_pair_idx'][0, 0]
            open_gt_valid_mask = ref_mat[i, 0]['open_gt_valid_mask'][0, 0]
            open_gt_256_64_idx = ref_mat[i, 0]['open_gt_256_64_idx'][0, 0]
            open_gt_type = ref_mat[i, 0]['open_gt_type'][0, 0] # Note: BSpline and Lines, so two label types: 1, 2
            open_type_onehot = ref_mat[i, 0]['open_type_onehot'][0, 0]
            open_gt_res = ref_mat[i, 0]['open_gt_res'][0, 0]
            open_gt_sample_points = ref_mat[i, 0]['open_gt_sample_points'][0, 0]
            open_gt_mask = ref_mat[i, 0]['open_gt_mask'][0, 0]
            closed_gt_256_64_idx = ref_mat[i, 0]['closed_gt_256_64_idx'][0, 0]
            closed_gt_mask = ref_mat[i, 0]['closed_gt_mask'][0, 0]
            closed_gt_type = ref_mat[i, 0]['closed_gt_type'][0, 0]
            closed_gt_res = ref_mat[i, 0]['closed_gt_res'][0, 0]
            closed_gt_sample_points = ref_mat[i, 0]['closed_gt_sample_points'][0, 0]
            closed_gt_valid_mask = ref_mat[i, 0]['closed_gt_valid_mask'][0, 0]
            closed_gt_pair_idx = ref_mat[i, 0]['closed_gt_pair_idx'][0, 0]
            tp = np.dtype([
                ('down_sample_point', 'O'),
                ('edge_points_label', 'O'),
                ('edge_points_residual_vector', 'O'),
                ('corner_points_label', 'O'),
                ('corner_points_residual_vector', 'O'),
                ('open_gt_pair_idx', 'O'),
                ('closed_gt_pair_idx', 'O'),
                ('open_gt_valid_mask', 'O'),
                ('closed_gt_valid_mask', 'O'),
                ('open_gt_256_64_idx', 'O'),
                ('closed_gt_256_64_idx', 'O'),
                ('open_gt_type','O'),
                ('closed_gt_type','O'),
                ('open_type_onehot','O'),
                ('open_gt_res', 'O'),
                ('closed_gt_res', 'O'),
                ('open_gt_sample_points', 'O'),
                ('closed_gt_sample_points', 'O'), 
                ('open_gt_mask', 'O'),
                ('closed_gt_mask', 'O')
                ])

            data['Training_data'][batch_count, 0] = np.zeros((1, 1), dtype = tp)
            for tp_name in tp.names: 
                save_this = locals()[tp_name]
                data['Training_data'][batch_count, 0][tp_name][0, 0] = save_this


            if batch_count == 63:
                # save mat
                file_ = str(file_count)+".mat"
                sio.savemat(file_, data)

                # renew batch_count
                batch_count = 0
                file_count = file_count + 1
                data = {'Training_data': np.zeros((64, 1), dtype = object)}
            else:
                batch_count = batch_count + 1

            i = i + 1
        
if __name__ == "__main__": 
    main()
